# ğŸ¤– Chat RAG HÃ­brido â€” OpenAI + Vectorizer + Flask

Este projeto integra **OpenAI GPT-4o-mini** com o **Vectorizer Server (Rust)**, criando um ambiente hÃ­brido de *Retrieval-Augmented Generation (RAG)* que combina **busca vetorial** e **geraÃ§Ã£o contextualizada** de respostas via LLM.

---

## ğŸ§  VisÃ£o Geral

O objetivo Ã© permitir que um modelo de linguagem (LLM) responda perguntas com base em **contextos vetorizados localmente**.  
Isso cria um pipeline de IA hÃ­brido:

> **UsuÃ¡rio â†’ Flask â†’ Vectorizer (busca semÃ¢ntica) â†’ OpenAI GPT-4o-mini â†’ Resposta contextualizada**

---

## ğŸš€ Tecnologias Utilizadas

| Camada | Ferramenta | DescriÃ§Ã£o |
|--------|-------------|-----------|
| ğŸ’¬ LLM | **OpenAI GPT-4o-mini** | Modelo de linguagem para geraÃ§Ã£o de respostas. |
| ğŸ” VetorizaÃ§Ã£o | **Vectorizer (Lucas Ferreira)** | Servidor Rust local para busca semÃ¢ntica. |
| ğŸ§  Backend | **Flask (Python 3.9)** | API intermediÃ¡ria que conecta OpenAI e Vectorizer. |
| âš™ï¸ Infraestrutura | **dotenv**, **requests**, **python-dotenv** | Gerenciamento de variÃ¡veis e integraÃ§Ã£o HTTP. |

---

## ğŸ§© Estrutura do Projeto

chat_rag_hybrid_v1/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ init.py # InicializaÃ§Ã£o do Flask + dotenv
â”‚ â”œâ”€â”€ routes/
â”‚ â”‚ â””â”€â”€ chat_rag.py # Endpoints / e /chat (integraÃ§Ã£o com OpenAI + Vectorizer)
â”‚ â””â”€â”€ utils/ # FunÃ§Ãµes auxiliares e integraÃ§Ã£o
â”œâ”€â”€ vectorizer/ # Servidor Rust (submÃ³dulo ou build local)
â”œâ”€â”€ tests/ # Scripts de teste de conexÃ£o e API
â”œâ”€â”€ run.py # Inicializa o servidor Flask
â”œâ”€â”€ requirements.txt # DependÃªncias Python
â”œâ”€â”€ .env # VariÃ¡veis de ambiente (nÃ£o versionado)
â””â”€â”€ README.md

yaml
Copiar cÃ³digo

---

## âš™ï¸ InstalaÃ§Ã£o

### 1ï¸âƒ£ Clonar o repositÃ³rio
```bash
git clone https://github.com/alvaromra/chat_rag_hybrid_v1.git
cd chat_rag_hybrid_v

2ï¸âƒ£ Criar ambiente virtual
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
